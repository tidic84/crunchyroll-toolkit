# Crunchyroll Scraper ğŸŒ

Un package Node.js puissant pour scraper les informations d'animÃ©s et les thumbnails d'Ã©pisodes depuis Crunchyroll avec des techniques avancÃ©es anti-dÃ©tection **2024/2025**.

## ğŸš€ Installation

```bash
npm install crunchyroll-scraper
```

ou avec Yarn :

```bash
yarn add crunchyroll-scraper
```

## âš ï¸ Protections Anti-Bot et Solutions

**Crunchyroll utilise des protections Cloudflare trÃ¨s strictes.** Ce package propose **4 types de scrapers** :

1. **ğŸš€ Scraper AvancÃ©** (`createCrunchyrollScraper`) : **NOUVEAU !** Techniques 2024/2025 pour contourner Cloudflare
2. **ğŸ›¡ï¸ Scraper Robuste** (`createRobustCrunchyrollScraper`) : Anti-dÃ©tection avec mode headless
3. **ğŸ“œ Scraper Legacy** (`createLegacyCrunchyrollScraper`) : Version basique pour tests
4. **ğŸ­ Scraper Demo** (`createDemoCrunchyrollScraper`) : DonnÃ©es d'exemple pour dÃ©veloppement

**Le scraper avancÃ© intÃ¨gre** : masquage WebDriver, simulation comportementale humaine, headers rÃ©alistes, techniques anti-empreinte digitale, et navigation furtive.

## ğŸ“‹ PrÃ©requis

- Node.js >= 14.0.0
- Chrome/Chromium installÃ© (requis par Playwright)

## ğŸ”§ Configuration

Le package utilise Playwright pour automatiser le navigateur. Lors de la premiÃ¨re installation, Playwright tÃ©lÃ©chargera automatiquement les navigateurs nÃ©cessaires.

Si vous rencontrez des problÃ¨mes, vous pouvez installer manuellement les dÃ©pendances de Playwright :

```bash
npx playwright install chromium
```

## ğŸ’¡ Utilisation

### ğŸš€ Scraper AvancÃ© (RECOMMANDÃ‰ - Nouvelles techniques 2024/2025)

```javascript
const { createCrunchyrollScraper } = require('crunchyroll-scraper');

async function scrapingAvance() {
  const scraper = await createCrunchyrollScraper({
    headless: false, // Mode visible pour Ã©viter la dÃ©tection
    timeout: 60000,  // Timeout plus long pour les challenges
    locale: 'fr-FR'
  });

  try {
    // Le scraper utilise automatiquement :
    // - Masquage des propriÃ©tÃ©s WebDriver/Playwright
    // - Simulation de comportement humain (souris, dÃ©lais)
    // - Headers HTTP rÃ©alistes
    // - Navigation furtive avec Ã©chauffement
    
    const searchResult = await scraper.searchAnime('One Piece');
    
    if (searchResult.success) {
      const anime = searchResult.data[0];
      console.log(`âœ… TrouvÃ©: ${anime.title}`);
      
      // RÃ©cupÃ©rer les Ã©pisodes avec techniques avancÃ©es
      const episodesResult = await scraper.getEpisodes(anime.url);
      console.log(`ğŸ“º ${episodesResult.data.length} Ã©pisodes trouvÃ©s`);
    }
  } finally {
    await scraper.close();
  }
}
```

### ğŸ›¡ï¸ Autres Options de Scrapers

```javascript
// Scraper robuste (headless avec anti-dÃ©tection)
const { createRobustCrunchyrollScraper } = require('crunchyroll-scraper');
const robustScraper = await createRobustCrunchyrollScraper();

// Scraper legacy (basique)
const { createLegacyCrunchyrollScraper } = require('crunchyroll-scraper');
const legacyScraper = await createLegacyCrunchyrollScraper();

// Scraper demo (donnÃ©es d'exemple)
const { createDemoCrunchyrollScraper } = require('crunchyroll-scraper');
const demoScraper = await createDemoCrunchyrollScraper();
```

### Utilisation avancÃ©e avec TypeScript

```typescript
import { CrunchyrollScraper, AnimeSeries } from 'crunchyroll-scraper';

const scraper = new CrunchyrollScraper({
  headless: false,  // Afficher le navigateur
  timeout: 60000,   // Timeout d'1 minute
  maxRetries: 3     // 3 tentatives max
});

await scraper.initialize();

// RÃ©cupÃ©rer une sÃ©rie complÃ¨te avec tous les dÃ©tails
const result = await scraper.getAnimeSeries('https://www.crunchyroll.com/series/...');

if (result.success) {
  const series: AnimeSeries = result.data;
  console.log(`${series.title} - ${series.episodeCount} Ã©pisodes`);
  
  // AccÃ©der aux thumbnails des Ã©pisodes
  series.episodes.forEach(episode => {
    console.log(`Episode ${episode.episodeNumber}: ${episode.thumbnail}`);
  });
}
```

## ğŸ“š API

### CrunchyrollScraper

#### Constructor Options

```typescript
interface ScraperOptions {
  headless?: boolean;      // Mode headless (dÃ©faut: true)
  timeout?: number;        // Timeout en ms (dÃ©faut: 30000)
  maxRetries?: number;     // Nombre de tentatives (dÃ©faut: 3)
  userAgent?: string;      // User agent personnalisÃ©
  locale?: string;         // Locale (dÃ©faut: 'fr-FR')
}
```

#### MÃ©thodes

##### `searchAnime(query: string): Promise<ScraperResult<Anime[]>>`

Recherche des animÃ©s par titre.

##### `getAnimeDetails(animeUrl: string): Promise<ScraperResult<Anime>>`

RÃ©cupÃ¨re les dÃ©tails d'un animÃ© (description, genres, annÃ©e, note).

##### `getEpisodes(animeUrl: string): Promise<ScraperResult<Episode[]>>`

RÃ©cupÃ¨re la liste des Ã©pisodes avec leurs thumbnails.

##### `getAnimeSeries(animeUrl: string): Promise<ScraperResult<AnimeSeries>>`

RÃ©cupÃ¨re les dÃ©tails de l'animÃ© ET tous ses Ã©pisodes en une seule fois.

### Types

```typescript
interface Anime {
  id: string;
  title: string;
  description?: string;
  thumbnail?: string;
  url: string;
  genres?: string[];
  releaseYear?: number;
  rating?: number;
  episodeCount?: number;
}

interface Episode {
  id: string;
  animeId: string;
  title: string;
  episodeNumber: number;
  seasonNumber?: number;
  thumbnail: string;
  description?: string;
  duration?: number;
  releaseDate?: Date;
  url: string;
}

interface ScraperResult<T> {
  success: boolean;
  data?: T;
  error?: string;
}
```

## ğŸ› ï¸ Exemples

### TÃ©lÃ©charger toutes les thumbnails d'une sÃ©rie

```javascript
const fs = require('fs');
const https = require('https');
const path = require('path');

async function downloadThumbnail(url, filepath) {
  return new Promise((resolve, reject) => {
    const file = fs.createWriteStream(filepath);
    https.get(url, response => {
      response.pipe(file);
      file.on('finish', () => {
        file.close();
        resolve();
      });
    }).on('error', reject);
  });
}

async function downloadAllThumbnails(animeUrl) {
  const scraper = await createCrunchyrollScraper();
  
  try {
    const result = await scraper.getAnimeSeries(animeUrl);
    
    if (result.success) {
      const series = result.data;
      const dir = `./thumbnails/${series.title.replace(/[^a-z0-9]/gi, '_')}`;
      
      if (!fs.existsSync(dir)) {
        fs.mkdirSync(dir, { recursive: true });
      }
      
      for (const episode of series.episodes) {
        const filename = `episode_${episode.episodeNumber}.jpg`;
        const filepath = path.join(dir, filename);
        
        await downloadThumbnail(episode.thumbnail, filepath);
        console.log(`âœ… TÃ©lÃ©chargÃ©: ${filename}`);
      }
    }
  } finally {
    await scraper.close();
  }
}
```

### Recherche et export en JSON

```javascript
async function exportAnimeData(searchQuery) {
  const scraper = await createCrunchyrollScraper();
  
  try {
    const searchResult = await scraper.searchAnime(searchQuery);
    
    if (searchResult.success && searchResult.data.length > 0) {
      const anime = searchResult.data[0];
      const seriesResult = await scraper.getAnimeSeries(anime.url);
      
      if (seriesResult.success) {
        const data = seriesResult.data;
        fs.writeFileSync(
          `${data.title.replace(/[^a-z0-9]/gi, '_')}.json`,
          JSON.stringify(data, null, 2)
        );
        console.log('âœ… DonnÃ©es exportÃ©es en JSON');
      }
    }
  } finally {
    await scraper.close();
  }
}
```

## âš ï¸ Limitations et considÃ©rations

1. **Rate Limiting** : Crunchyroll peut limiter le nombre de requÃªtes. Utilisez des dÃ©lais entre les requÃªtes.

2. **Changements de structure** : Le site peut changer sa structure HTML. Le package sera mis Ã  jour rÃ©guliÃ¨rement.

3. **Respect des CGU** : Assurez-vous de respecter les conditions d'utilisation de Crunchyroll.

4. **Performance** : Le scraping peut Ãªtre lent pour les grandes sÃ©ries. Utilisez le mode headless pour de meilleures performances.

## ğŸ¤ Contribution

Les contributions sont les bienvenues ! N'hÃ©sitez pas Ã  :

1. Fork le projet
2. CrÃ©er une branche (`git checkout -b feature/AmazingFeature`)
3. Commit vos changements (`git commit -m 'Add some AmazingFeature'`)
4. Push sur la branche (`git push origin feature/AmazingFeature`)
5. Ouvrir une Pull Request

## ğŸ“„ Licence

Ce projet est sous licence MIT. Voir le fichier [LICENSE](LICENSE) pour plus de dÃ©tails.

## ğŸ™ Remerciements

- [Playwright](https://playwright.dev/) pour l'automatisation du navigateur
- [TypeScript](https://www.typescriptlang.org/) pour le typage statique
- La communautÃ© anime pour le support et les retours

## ğŸ“ Support

Pour toute question ou problÃ¨me, ouvrez une issue sur GitHub.

---

**Note** : Ce package est un outil Ã©ducatif. Utilisez-le de maniÃ¨re responsable et respectez les droits d'auteur. 